<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><!-- hexo injector head_begin start -->
<link rel="stylesheet" href="/css/bilicard.css">
<!-- hexo injector head_begin end --><div id="myscoll"></div><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>LangChain入门指南 | Kyle's Blog</title><meta name="keywords" content="LangChain"><meta name="author" content="Kyle Violet"><meta name="copyright" content="Kyle Violet"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="什么是LangChain  LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如 API 和数据库。 官方文档：https:&#x2F;&#x2F;python.langchain.com">
<meta property="og:type" content="article">
<meta property="og:title" content="LangChain入门指南">
<meta property="og:url" content="https://cyborg2077.github.io/2024/01/26/LangChainPrimer/index.html">
<meta property="og:site_name" content="Kyle&#39;s Blog">
<meta property="og:description" content="什么是LangChain  LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如 API 和数据库。 官方文档：https:&#x2F;&#x2F;python.langchain.com">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img0.baidu.com/it/u=1415156609,1199509453&fm=253&fmt=auto&app=120&f=JPEG?w=949&h=500">
<meta property="article:published_time" content="2024-01-26T03:27:30.000Z">
<meta property="article:modified_time" content="2024-02-24T05:54:08.000Z">
<meta property="article:author" content="Kyle Violet">
<meta property="article:tag" content="LangChain">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img0.baidu.com/it/u=1415156609,1199509453&fm=253&fmt=auto&app=120&f=JPEG?w=949&h=500"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://cyborg2077.github.io/2024/01/26/LangChainPrimer/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?d54c3018e5f620d2cda0f5ca52ff80cb";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.js',
      css: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LangChain入门指南',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-24 13:54:08'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn1.tianli0.top/npm/element-ui@2.15.6/packages/theme-chalk/lib/index.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_3049706_m3wrww27lm.css"><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><script src='//unpkg.com/valine/dist/Valine.min.js'></script><style id="themeColor"></style><style id="rightSide"></style><style id="transPercent"></style><style id="blurNum"></style><style id="settingStyle"></style><style id="defineBg"></style><style id="menu_shadow"></style><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu@1.1.6/lib/clock.min.css" /><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Kyle's Blog" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2025/02/23/AMkCrfzyFsBQE3D.png" onerror="onerror=null;src='/assets/r1.png'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">151</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">112</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-HOME"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-exe-article-primary"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang1">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-tags">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-ziyuan1"></use></svg><span class="menu_word" style="font-size:17px"> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/box/fitness/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-tiyu">                   </use></svg><span class="menu_word" style="font-size:17px"> 健身日寄</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/animation/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-nvwumao">                   </use></svg><span class="menu_word" style="font-size:17px"> 番剧</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/secret/"><i class="fa-fw fas fa-heart faa-tada"></i><span class="menu_word" style="font-size:17px"> 记忆胶囊</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shejiaoxinxi"></use></svg><span class="menu_word" style="font-size:17px"> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan">                   </use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/link/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-lianjie">                   </use></svg><span class="menu_word" style="font-size:17px"> 友人帐</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-maoliang"></use></svg><span class="menu_word" style="font-size:17px"> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/moments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-qunliaotian">                   </use></svg><span class="menu_word" style="font-size:17px"> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-geren-dangqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 关于我</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/pumpkin/"><i class="fa-fw fas fa-pumpkin fas fa-heart"></i><span class="menu_word" style="font-size:17px"> Pumpkin</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Kyle's Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-HOME"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-exe-article-primary"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang1">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-tags">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-ziyuan1"></use></svg><span class="menu_word" style="font-size:17px"> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/box/fitness/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-tiyu">                   </use></svg><span class="menu_word" style="font-size:17px"> 健身日寄</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/animation/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-nvwumao">                   </use></svg><span class="menu_word" style="font-size:17px"> 番剧</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/secret/"><i class="fa-fw fas fa-heart faa-tada"></i><span class="menu_word" style="font-size:17px"> 记忆胶囊</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shejiaoxinxi"></use></svg><span class="menu_word" style="font-size:17px"> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan">                   </use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/link/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-lianjie">                   </use></svg><span class="menu_word" style="font-size:17px"> 友人帐</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-maoliang"></use></svg><span class="menu_word" style="font-size:17px"> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/moments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-qunliaotian">                   </use></svg><span class="menu_word" style="font-size:17px"> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-geren-dangqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 关于我</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/pumpkin/"><i class="fa-fw fas fa-pumpkin fas fa-heart"></i><span class="menu_word" style="font-size:17px"> Pumpkin</span></a></li></ul></div></div><center id="name-container"><a id="page-name" href="javascript:scrollToTop()">PAGE_NAME</a></center><div id="nav-right"><div id="search-button"><a class="search faa-parent animated-hover" title="检索站内任何你想要的信息"><svg class="faa-tada icon" style="height:24px;width:24px;fill:currentColor;position:relative;top:6px" aria-hidden="true"><use xlink:href="#icon-valentine_-search-love-find-heart"></use></svg><span> 搜索</span></a></div><a class="meihua faa-parent animated-hover" onclick="toggleWinbox()" title="美化设置-自定义你的风格" id="meihua-button"><svg class="faa-tada icon" style="height:26px;width:26px;fill:currentColor;position:relative;top:8px" aria-hidden="true"><use xlink:href="#icon-tupian1"></use></svg></a><a class="sun_moon faa-parent animated-hover" onclick="switchNightMode()" title="浅色和深色模式转换" id="nightmode-button"><svg class="faa-tada" style="height:25px;width:25px;fill:currentColor;position:relative;top:7px" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon">       </use></svg></a><div id="toggle-menu"><a><i class="fas fa-bars fa-fw"></i></a></div></div></div></nav><div id="post-info"><h1 class="post-title">LangChain入门指南</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><svg class="meta_icon post-meta-icon" style="width:30px;height:30px;position:relative;top:10px"><use xlink:href="#icon-rili"></use></svg><span class="post-meta-label">发表于 </span><time class="post-meta-date-created" datetime="2024-01-26T03:27:30.000Z" title="发表于 2024-01-26 11:27:30">2024-01-26</time><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-gengxin1"></use></svg><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-24T05:54:08.000Z" title="更新于 2024-02-24 13:54:08">2024-02-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-biaoqian"></use></svg><a class="post-meta-categories" href="/categories/%E5%AE%9E%E7%94%A8%E6%95%99%E7%A8%8B/">实用教程</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:8px"><use xlink:href="#icon-charuword"></use></svg><span class="post-meta-label">字数总计:</span><span class="word-count">1.8w</span><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:20px;height:20px;position:relative;top:5px"><use xlink:href="#icon-shizhong"></use></svg><span class="post-meta-label">阅读时长:</span><span>85分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="LangChain入门指南"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:5px"><use xlink:href="#icon-eye"></use></svg><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>什么是LangChain</h1>
<ul>
<li>LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如 API 和数据库。</li>
<li>官方文档：<a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/">https://python.langchain.com/en/latest/</a></li>
</ul>
<h1>如何使用LangChain</h1>
<ul>
<li>要使用 LangChain，开发人员首先要导入必要的组件和工具，例如 LLMs, chat models, agents, chains, 内存功能。这些组件组合起来创建一个可以理解、处理和响应用户输入的应用程序。</li>
<li>LangChain 为特定用例提供了多种组件，例如个人助理、文档问答、聊天机器人、查询表格数据、与 API 交互、提取、评估和汇总。</li>
</ul>
<h1>LangChain的模型</h1>
<ul>
<li>LangChain model 是一种抽象，表示框架中使用的不同类型的模型。LangChain 中的模型主要分为三类：
<ol>
<li>LLM（大型语言模型）：这些模型将文本字符串作为输入并返回文本字符串作为输出。它们是许多语言模型应用程序的支柱。</li>
<li>聊天模型( Chat Model)：聊天模型由语言模型支持，但具有更结构化的 API。他们将聊天消息列表作为输入并返回聊天消息。这使得管理对话历史记录和维护上下文变得容易。</li>
<li>文本嵌入模型(Text Embedding Models)：这些模型将文本作为输入并返回表示文本嵌入的浮点列表。这些嵌入可用于文档检索、聚类和相似性比较等任务。</li>
</ol>
</li>
</ul>
<h1>LangChain 的主要特点</h1>
<ul>
<li>LangChain 旨在为六个主要领域的开发人员提供支持：
<ol>
<li>LLM 和提示：LangChain 使管理提示、优化它们以及为所有 LLM 创建通用界面变得容易。此外，它还包括一些用于处理 LLM 的便捷实用程序。</li>
<li>链(Chain)：这些是对 LLM 或其他实用程序的调用序列。LangChain 为链提供标准接口，与各种工具集成，为流行应用提供端到端的链。</li>
<li>数据增强生成：LangChain 使链能够与外部数据源交互以收集生成步骤的数据。例如，它可以帮助总结长文本或使用特定数据源回答问题。</li>
<li>Agents：Agents 让 LLM 做出有关行动的决定，采取这些行动，检查结果，并继续前进直到工作完成。LangChain 提供了代理的标准接口，多种代理可供选择，以及端到端的代理示例。</li>
<li>内存：LangChain 有一个标准的内存接口，有助于维护链或代理调用之间的状态。它还提供了一系列内存实现和使用内存的链或代理的示例。</li>
<li>评估：很难用传统指标评估生成模型。这就是为什么 LangChain 提供提示和链来帮助开发者自己使用 LLM 评估他们的模型。</li>
</ol>
</li>
</ul>
<h1>使用示例</h1>
<h2 id="提示模板（PromptTemplate）">提示模板（PromptTemplate）</h2>
<ol>
<li>支持我们来自定义提示模板，不会将用户输入直接发送到 LLM，而是接收用户的输入，然后构造一个prompt将其发送给 LLM。</li>
</ol>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts import PromptTemplate</span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;paperTitle&quot;</span>, <span class="string">&quot;area&quot;</span>, <span class="string">&quot;nums&quot;</span>, <span class="string">&quot;keywords&quot;</span>],</span><br><span class="line">    <span class="attribute">template</span>=<span class="string">&quot;我想让你充当&#123;area&#125;领域的专家，针对于&#123;paperTitle&#125;这个主题，帮我撰写一篇&#123;nums&#125;字的文献综述。包含的关键字如下：&#123;keywords&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(prompt.format(<span class="attribute">paperTitle</span>=<span class="string">&quot;大学生网红产品消费行为研究&quot;</span>, <span class="attribute">area</span>=<span class="string">&quot;经济学&quot;</span>, <span class="attribute">nums</span>=500, <span class="attribute">keywords</span>=<span class="string">&quot;大学生、网红、消费、行为研究&quot;</span>))</span><br><span class="line"><span class="comment"># 输出：我想让你充当经济学领域的专家，针对于大学生网红产品消费行为研究这个主题，帮我撰写一篇500字的文献综述。包含的关键字如下：大学生、网红、消费、行为研究</span></span><br></pre></td></tr></table></figure>
<h2 id="LLM-Chain">LLM Chain</h2>
<ul>
<li>我们可以把初始化好的LLM和Template，组合成一个chain</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 初始化llm</span></span><br><span class="line">llm = ChatOpenAI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里其实就可以直接调用llm了</span></span><br><span class="line">llm.invoke(<span class="string">&quot;how can langsmith help with testing?&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 这里可以初始化一个模板</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是世界上最好的科幻小说作者&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;user&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 采用这种方式可以将llm和template组合成一个chain</span></span><br><span class="line">chain = prompt | llm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 调用组合后的chain</span></span><br><span class="line">chain.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;你对LangSmith了解吗？&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="Retrieval-Chain（基于检索的chain）">Retrieval Chain（基于检索的chain）</h2>
<ul>
<li>当你需要让LLM回答一个问题时（比如 “how can langsmith help with testing?”），有时候你要提供的提示信息可能太多，直接传递给语言模型可能不够有效。为了提供更多上下文，LangChain提供了通过检索（retrieval）的方式获取相关的文档，并将这些文档传递给语言模型。</li>
<li>在这个过程中，我们使用一个检索器（Retriever）来查找相关的文档，然后将这些文档传递给提示模板。检索器可以由各种数据支持，比如一个 SQL 表、互联网上的数据等，但在官网的Demo里，将使用一个向量存储（vector store）来作为检索器。</li>
<li>首先，我们需要加载要索引的数据。为了做到这一点，我们将使用 WebBaseLoader（这个应该是LangChain内部实现的一个爬虫工具，要依赖于BeautifulSoup<br>
pip install beautifulsoup4</li>
<li>引入WebBaseLocder来爬取内容</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> WebBaseLoader</span><br><span class="line"></span><br><span class="line">loader = WebBaseLoader(<span class="string">&quot;https://docs.smith.langchain.com/overview&quot;</span>)</span><br><span class="line">docs = loader.load()</span><br><span class="line"><span class="built_in">print</span>(docs)</span><br><span class="line"><span class="comment"># [Document(page_content=&#x27;\n\n\n\n\nLangSmith Overview and User Guide | 🦜️🛠️ LangSmith\n\n\n\n\n\nSkip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting &amp; EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmith’s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript environments through process.env1.The benefit here is that all calls to LLMs, chains, agents, tools, and retrievers are logged to LangSmith. Around 90% of the time we don’t even look at the traces, but the 10% of the time that we do… it’s so helpful. We can use LangSmith to debug:An unexpected end resultWhy an agent is loopingWhy a chain was slower than expectedHow many tokens an agent usedDebugging\u200bDebugging LLMs, chains, and agents can be tough. LangSmith helps solve the following pain points:What was the exact input to the LLM?\u200bLLM calls are often tricky and non-deterministic. The inputs/outputs may seem straightforward, given they are technically string → string (or chat messages → chat message), but this can be misleading as the input string is usually constructed from a combination of user input and auxiliary functions.Most inputs to an LLM call are a combination of some type of fixed template along with input variables. These input variables could come directly from user input or from an auxiliary function (like retrieval). By the time these input variables go into the LLM they will have been converted to a string format, but often times they are not naturally represented as a string (they could be a list, or a Document object). Therefore, it is important to have visibility into what exactly the final string going into the LLM is. This has helped us debug bugs in formatting logic, unexpected transformations to user input, and straight up missing user input.To a much lesser extent, this is also true of the output of an LLM. Oftentimes the output of an LLM is technically a string but that string may contain some structure (json, yaml) that is intended to be parsed into a structured representation. Understanding what the exact output is can help determine if there may be a need for different parsing.LangSmith provides a straightforward visualization of the exact inputs/outputs to all LLM calls, so you can easily understand them.If I edit the prompt, how does that affect the output?\u200bSo you notice a bad output, and you go into LangSmith to see what\&#x27;s going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being made? In what order? What are the inputs and outputs of each call?LangSmith\&#x27;s built-in tracing feature offers a visualization to clarify these sequences. This tool is invaluable for understanding intricate and lengthy chains and agents. For chains, it can shed light on the sequence of calls and how they interact. For agents, where the sequence of calls is non-deterministic, it helps visualize the specific sequence for a given run -- something that is impossible to know ahead of time.Why did my chain take much longer than expected?\u200bIf a chain takes longer than expected, you need to identify the cause. By tracking the latency of each step, LangSmith lets you identify and possibly eliminate the slowest components.How many tokens were used?\u200bBuilding and prototyping LLM applications can be expensive. LangSmith tracks the total token usage for a chain and the token usage of each step. This makes it easy to identify potentially costly parts of the chain.Collaborative debugging\u200bIn the past, sharing a faulty chain with a colleague for debugging was challenging when performed locally. With LangSmith, we\&#x27;ve added a “Share” button that makes the chain and LLM runs accessible to anyone with the shared link.Collecting examples\u200bMost of the time we go to debug, it\&#x27;s because something bad or unexpected outcome has happened in our application. These failures are valuable data points! By identifying how our chain can fail and monitoring these failures, we can test future chain versions against these known issues.Why is this so impactful? When building LLM applications, it’s often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you\&#x27;re wandering blind. You don’t have any examples to benchmark your changes against.LangSmith addresses this problem by including an “Add to Dataset” button for each run, making it easy to add the input/output examples a chosen dataset. You can edit the example before adding them to the dataset to include the expected result, which is particularly useful for bad examples.This feature is available at every step of a nested chain, enabling you to add examples for an end-to-end chain, an intermediary chain (such as a LLM Chain), or simply the LLM or Chat Model.End-to-end chain examples are excellent for testing the overall flow, while single, modular LLM Chain or LLM/Chat Model examples can be beneficial for testing the simplest and most directly modifiable components.Testing &amp; evaluation\u200bInitially, we do most of our evaluation manually and ad hoc. We pass in different\ninputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat we’ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies\ndataset uploading.Once we have a dataset, how can we use it to test changes to a prompt or chain? The most basic approach is to run the chain over the data points and visualize the outputs. Despite technological advancements, there still is no substitute for looking at outputs by eye. Currently, running the chain over the data points needs to be done client-side. The LangSmith client makes it easy to pull down a dataset and then run a chain over them, logging the results to a new project associated with the dataset. From there, you can review them. We\&#x27;ve made it easy to assign feedback to runs and mark them as correct or incorrect directly in the web app, displaying aggregate statistics for each test project.We also make it easier to evaluate these runs. To that end, we\&#x27;ve added a set of evaluators to the open-source LangChain library. These evaluators can be specified when initiating a test run and will evaluate the results once the test run completes. If we’re being honest, most of these evaluators aren\&#x27;t perfect. We would not recommend that you trust them blindly. However, we do think they are useful for guiding your eye to examples you should look at. This becomes especially valuable as the number of data points increases and it becomes infeasible to look at each one manually.Human Evaluation\u200bAutomatic evaluation metrics are helpful for getting consistent and scalable information about model behavior;\nhowever, there is still no complete substitute for human review to get the utmost quality and reliability from your application.\nLangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like creativity or humorTo sample and validate a subset of runs that were auto-evaluated, ensuring the automatic metrics are still reliable and capturing the right informationAll the annotations made using the queue are assigned as &quot;feedback&quot; to the source runs, so you can easily filter and analyze them later.\nYou can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.We’ve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing — mirroring the debug mode approach.We’ve provided several examples in the LangSmith documentation for extracting insights from logged runs. In addition to guiding you on performing this task yourself, we also provide examples of integrating with third parties for this purpose. We\&#x27;re eager to expand this area in the coming months! If you have ideas for either -- an open-source way to evaluate, or are building a company that wants to do analytics over these runs, please reach out.Exporting datasets\u200bLangSmith makes it easy to curate datasets. However, these aren’t just useful inside LangSmith; they can be exported for use in other contexts. Notable applications include exporting for use in OpenAI Evals or fine-tuning, such as with FireworksAI.To set up tracing in Deno, web browsers, or other runtime environments without access to the environment, check out the FAQs.↩PreviousLangSmithNextTracingOn by defaultDebuggingWhat was the exact input to the LLM?If I edit the prompt, how does that affect the output?What is the exact sequence of events?Why did my chain take much longer than expected?How many tokens were used?Collaborative debuggingCollecting examplesTesting &amp; evaluationHuman EvaluationMonitoringExporting datasetsCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\n\n\n\n&#x27;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;)]</span></span><br><span class="line"><span class="comment"># 这里输出的docs就是网页上的内容</span></span><br></pre></td></tr></table></figure>
<ul>
<li>然后我们需要将这些文档索引到一个向量存储中。这需要一些组件，包括嵌入模型（embedding model）和向量存储。
<ol>
<li>检索器（Retriever）： 想象一下你在图书馆找书的时候，你可能不会把整个图书馆的书都拿去看。相反，你可能会咨询图书管理员或者查找图书馆的目录，找到与你问题相关的书籍。在这里，检索器就像图书馆的目录，它帮助我们找到与问题相关的信息。</li>
<li>向量存储（Vector Store）： 这就像一个大仓库，里面存放着各种各样的信息。每个信息都用一个向量表示，就像是仓库中的一个箱子。通过这些向量，我们可以快速找到存储库中与我们关心的主题相关的信息。</li>
<li>嵌入模型（Embedding Model）： 这就像是一个翻译工人，它将文档中的文字翻译成计算机能够理解的形式，也就是向量。这样，计算机就能够更好地处理和比较文档，找到最相关的信息。</li>
</ol>
</li>
</ul>
<h2 id="根据文档构建向量">根据文档构建向量</h2>
<ol>
<li>使用 OpenAIEmbeddings 初始化一个嵌入模型，用于将文档转化为向量。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"></span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>使用一个简单的本地向量存储 FAISS 来建立索引.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install faiss-cpu</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>构建向量存储</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文本分割器</span></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter()</span><br><span class="line"><span class="comment"># 将刚刚获取的docs分割，输出是一个List&lt;String&gt;的类型</span></span><br><span class="line">documents = text_splitter.split_documents(docs)</span><br><span class="line"><span class="comment"># 根据嵌入模型和分割后的文档，转换为向量</span></span><br><span class="line">vector = FAISS.from_documents(documents, embeddings)</span><br></pre></td></tr></table></figure>
<h2 id="构建链">构建链</h2>
<ol>
<li>构建一个链，该链接受问题和检索到的文档，生成答案：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains.combine_documents <span class="keyword">import</span> create_stuff_documents_chain</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"></span><br><span class="line">prompt = ChatPromptTemplate.from_template(<span class="string">&quot;&quot;&quot;Answer the following question based only on the provided context:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;context&gt;</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">&lt;/context&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: &#123;input&#125;&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">document_chain = create_stuff_documents_chain(llm, prompt)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>使用检索器动态选择最相关的文档并传递给链：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> create_retrieval_chain</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里的vector是我们第一步构建的向量，将其转换为检索器</span></span><br><span class="line">retriever = vector.as_retriever()</span><br><span class="line">retrieval_chain = create_retrieval_chain(retriever, document_chain)</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>调用这个链，来获取响应结果，这个答案应该更加准确，因为它结合了检索到的相关文档和原始问题。这整个过程就是为了使得语言模型在回答问题时能够基于更全面的上下文信息。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = retrieval_chain.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;how can langsmith help with testing?&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="完整demo">完整demo</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> create_retrieval_chain</span><br><span class="line"><span class="keyword">from</span> langchain.chains.combine_documents <span class="keyword">import</span> create_stuff_documents_chain</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> WebBaseLoader</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms.ollama <span class="keyword">import</span> Ollama</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores.faiss <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> OllamaEmbeddings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">llm = Ollama(model=<span class="string">&quot;llama2&quot;</span>)</span><br><span class="line"><span class="comment"># 初始化嵌入模型</span></span><br><span class="line"></span><br><span class="line">embeddings = OllamaEmbeddings()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬取内容</span></span><br><span class="line">loader = WebBaseLoader(<span class="string">&quot;https://docs.smith.langchain.com/overview&quot;</span>)</span><br><span class="line">docs = loader.load()</span><br><span class="line"><span class="built_in">print</span>(docs)</span><br><span class="line"><span class="comment"># 文本分割器</span></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter()</span><br><span class="line"><span class="comment"># 将刚刚获取的docs分割</span></span><br><span class="line">documents = text_splitter.split_documents(docs)</span><br><span class="line"><span class="built_in">print</span>(documents)</span><br><span class="line"><span class="comment"># 根据嵌入模型和分割后的文档，转换为向量</span></span><br><span class="line">vector = FAISS.from_documents(documents, embeddings)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;转换成向量完毕&quot;</span>)</span><br><span class="line"><span class="comment"># 将向量转换为检索器</span></span><br><span class="line">retriever = vector.as_retriever()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;将向量转换为检索器&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建问题链</span></span><br><span class="line">prompt = ChatPromptTemplate.from_template(<span class="string">&quot;&quot;&quot;Answer the following question based only on the provided context:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;context&gt;</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">&lt;/context&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: &#123;input&#125;&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">document_chain = create_stuff_documents_chain(llm, prompt)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;构建问题完毕&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用检索器动态选择最相关的文档并传递给链：</span></span><br><span class="line">retrieval_chain = create_retrieval_chain(retriever, document_chain)</span><br><span class="line"><span class="comment"># 最终调用</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;开始调用&quot;</span>)</span><br><span class="line"></span><br><span class="line">response = retrieval_chain.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;how can langsmith help with testing?&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;调用完毕&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>
<ul>
<li>输出如下</li>
</ul>
<figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[Document(page_content=<span class="comment">&#x27;\n\n\n\n\nLangSmith Overview and User Guide | 🦜️🛠️ LangSmith\n\n\n\n\n\nSkip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting &amp; EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmith’s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript environments through process.env1.The benefit here is that all calls to LLMs, chains, agents, tools, and retrievers are logged to LangSmith. Around 90% of the time we don’t even look at the traces, but the 10% of the time that we do… it’s so helpful. We can use LangSmith to de<span class="doctag">bug:</span>An unexpected end resultWhy an agent is loopingWhy a chain was slower than expectedHow many tokens an agent usedDebugging\u200bDebugging LLMs, chains, and agents can be tough. LangSmith helps solve the following pain points:What was the exact input to the LLM?\u200bLLM calls are often tricky and non-deterministic. The inputs/outputs may seem straightforward, given they are technically string → string (or chat messages → chat message), but this can be misleading as the input string is usually constructed from a combination of user input and auxiliary functions.Most inputs to an LLM call are a combination of some type of fixed template along with input variables. These input variables could come directly from user input or from an auxiliary function (like retrieval). By the time these input variables go into the LLM they will have been converted to a string format, but often times they are not naturally represented as a string (they could be a list, or a Document object). Therefore, it is important to have visibility into what exactly the final string going into the LLM is. This has helped us debug bugs in formatting logic, unexpected transformations to user input, and straight up missing user input.To a much lesser extent, this is also true of the output of an LLM. Oftentimes the output of an LLM is technically a string but that string may contain some structure (json, yaml) that is intended to be parsed into a structured representation. Understanding what the exact output is can help determine if there may be a need for different parsing.LangSmith provides a straightforward visualization of the exact inputs/outputs to all LLM calls, so you can easily understand them.If I edit the prompt, how does that affect the output?\u200bSo you notice a bad output, and you go into LangSmith to see what\&#x27;s going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being made? In what order? What are the inputs and outputs of each call?LangSmith\&#x27;s built-in tracing feature offers a visualization to clarify these sequences. This tool is invaluable for understanding intricate and lengthy chains and agents. For chains, it can shed light on the sequence of calls and how they interact. For agents, where the sequence of calls is non-deterministic, it helps visualize the specific sequence for a given run -- something that is impossible to know ahead of time.Why did my chain take much longer than expected?\u200bIf a chain takes longer than expected, you need to identify the cause. By tracking the latency of each step, LangSmith lets you identify and possibly eliminate the slowest components.How many tokens were used?\u200bBuilding and prototyping LLM applications can be expensive. LangSmith tracks the total token usage for a chain and the token usage of each step. This makes it easy to identify potentially costly parts of the chain.Collaborative debugging\u200bIn the past, sharing a faulty chain with a colleague for debugging was challenging when performed locally. With LangSmith, we\&#x27;ve added a “Share” button that makes the chain and LLM runs accessible to anyone with the shared link.Collecting examples\u200bMost of the time we go to debug, it\&#x27;s because something bad or unexpected outcome has happened in our application. These failures are valuable data points! By identifying how our chain can fail and monitoring these failures, we can test future chain versions against these known issues.Why is this so impactful? When building LLM applications, it’s often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you\&#x27;re wandering blind. You don’t have any examples to benchmark your changes against.LangSmith addresses this problem by including an “Add to Dataset” button for each run, making it easy to add the input/output examples a chosen dataset. You can edit the example before adding them to the dataset to include the expected result, which is particularly useful for bad examples.This feature is available at every step of a nested chain, enabling you to add examples for an end-to-end chain, an intermediary chain (such as a LLM Chain), or simply the LLM or Chat Model.End-to-end chain examples are excellent for testing the overall flow, while single, modular LLM Chain or LLM/Chat Model examples can be beneficial for testing the simplest and most directly modifiable components.Testing &amp; evaluation\u200bInitially, we do most of our evaluation manually and ad hoc. We pass in different\ninputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat we’ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies\ndataset uploading.Once we have a dataset, how can we use it to test changes to a prompt or chain? The most basic approach is to run the chain over the data points and visualize the outputs. Despite technological advancements, there still is no substitute for looking at outputs by eye. Currently, running the chain over the data points needs to be done client-side. The LangSmith client makes it easy to pull down a dataset and then run a chain over them, logging the results to a new project associated with the dataset. From there, you can review them. We\&#x27;ve made it easy to assign feedback to runs and mark them as correct or incorrect directly in the web app, displaying aggregate statistics for each test project.We also make it easier to evaluate these runs. To that end, we\&#x27;ve added a set of evaluators to the open-source LangChain library. These evaluators can be specified when initiating a test run and will evaluate the results once the test run completes. If we’re being honest, most of these evaluators aren\&#x27;t perfect. We would not recommend that you trust them blindly. However, we do think they are useful for guiding your eye to examples you should look at. This becomes especially valuable as the number of data points increases and it becomes infeasible to look at each one manually.Human Evaluation\u200bAutomatic evaluation metrics are helpful for getting consistent and scalable information about model behavior;\nhowever, there is still no complete substitute for human review to get the utmost quality and reliability from your application.\nLangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like creativity or humorTo sample and validate a subset of runs that were auto-evaluated, ensuring the automatic metrics are still reliable and capturing the right informationAll the annotations made using the queue are assigned as &quot;feedback&quot; to the source runs, so you can easily filter and analyze them later.\nYou can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.We’ve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing — mirroring the debug mode approach.We’ve provided several examples in the LangSmith documentation for extracting insights from logged runs. In addition to guiding you on performing this task yourself, we also provide examples of integrating with third parties for this purpose. We\&#x27;re eager to expand this area in the coming months! If you have ideas for either -- an open-source way to evaluate, or are building a company that wants to do analytics over these runs, please reach out.Exporting datasets\u200bLangSmith makes it easy to curate datasets. However, these aren’t just useful inside LangSmith; they can be exported for use in other contexts. Notable applications include exporting for use in OpenAI Evals or fine-tuning, such as with FireworksAI.To set up tracing in Deno, web browsers, or other runtime environments without access to the environment, check out the FAQs.↩PreviousLangSmithNextTracingOn by defaultDebuggingWhat was the exact input to the LLM?If I edit the prompt, how does that affect the output?What is the exact sequence of events?Why did my chain take much longer than expected?How many tokens were used?Collaborative debuggingCollecting examplesTesting &amp; evaluationHuman EvaluationMonitoringExporting datasetsCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\n\n\n\n&#x27;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;)]</span></span><br><span class="line">[Document(page_content=<span class="comment">&#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;), Document(page_content=&quot;Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting &amp; EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmith’s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript environments through process.env1.The benefit here is that all calls to LLMs, chains, agents, tools, and retrievers are logged to LangSmith. Around 90% of the time we don’t even look at the traces, but the 10% of the time that we do… it’s so helpful. We can use LangSmith to de<span class="doctag">bug:</span>An unexpected end resultWhy an agent is loopingWhy a chain was slower than expectedHow many tokens an agent usedDebugging\u200bDebugging LLMs, chains, and agents can be tough. LangSmith helps solve the following pain points:What was the exact input to the LLM?\u200bLLM calls are often tricky and non-deterministic. The inputs/outputs may seem straightforward, given they are technically string → string (or chat messages → chat message), but this can be misleading as the input string is usually constructed from a combination of user input and auxiliary functions.Most inputs to an LLM call are a combination of some type of fixed template along with input variables. These input variables could come directly from user input or from an auxiliary function (like retrieval). By the time these input variables go into the LLM they will have been converted to a string format, but often times they are not naturally represented as a string (they could be a list, or a Document object). Therefore, it is important to have visibility into what exactly the final string going into the LLM is. This has helped us debug bugs in formatting logic, unexpected transformations to user input, and straight up missing user input.To a much lesser extent, this is also true of the output of an LLM. Oftentimes the output of an LLM is technically a string but that string may contain some structure (json, yaml) that is intended to be parsed into a structured representation. Understanding what the exact output is can help determine if there may be a need for different parsing.LangSmith provides a straightforward visualization of the exact inputs/outputs to all LLM calls, so you can easily understand them.If I edit the prompt, how does that affect the output?\u200bSo you notice a bad output, and you go into LangSmith to see what&#x27;s going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being made? In what&quot;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;), Document(page_content=&quot;retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being made? In what order? What are the inputs and outputs of each call?LangSmith&#x27;s built-in tracing feature offers a visualization to clarify these sequences. This tool is invaluable for understanding intricate and lengthy chains and agents. For chains, it can shed light on the sequence of calls and how they interact. For agents, where the sequence of calls is non-deterministic, it helps visualize the specific sequence for a given run -- something that is impossible to know ahead of time.Why did my chain take much longer than expected?\u200bIf a chain takes longer than expected, you need to identify the cause. By tracking the latency of each step, LangSmith lets you identify and possibly eliminate the slowest components.How many tokens were used?\u200bBuilding and prototyping LLM applications can be expensive. LangSmith tracks the total token usage for a chain and the token usage of each step. This makes it easy to identify potentially costly parts of the chain.Collaborative debugging\u200bIn the past, sharing a faulty chain with a colleague for debugging was challenging when performed locally. With LangSmith, we&#x27;ve added a “Share” button that makes the chain and LLM runs accessible to anyone with the shared link.Collecting examples\u200bMost of the time we go to debug, it&#x27;s because something bad or unexpected outcome has happened in our application. These failures are valuable data points! By identifying how our chain can fail and monitoring these failures, we can test future chain versions against these known issues.Why is this so impactful? When building LLM applications, it’s often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you&#x27;re wandering blind. You don’t have any examples to benchmark your changes against.LangSmith addresses this problem by including an “Add to Dataset” button for each run, making it easy to add the input/output examples a chosen dataset. You can edit the example before adding them to the dataset to include the expected result, which is particularly useful for bad examples.This feature is available at every step of a nested chain, enabling you to add examples for an end-to-end chain, an intermediary chain (such as a LLM Chain), or simply the LLM or Chat Model.End-to-end chain examples are excellent for testing the overall flow, while single, modular LLM Chain or LLM/Chat Model examples can be beneficial for testing the simplest and most directly modifiable components.Testing &amp; evaluation\u200bInitially, we do most of our evaluation manually and ad hoc. We pass in different&quot;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;), Document(page_content=&#x27;inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat we’ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies\ndataset uploading.Once we have a dataset, how can we use it to test changes to a prompt or chain? The most basic approach is to run the chain over the data points and visualize the outputs. Despite technological advancements, there still is no substitute for looking at outputs by eye. Currently, running the chain over the data points needs to be done client-side. The LangSmith client makes it easy to pull down a dataset and then run a chain over them, logging the results to a new project associated with the dataset. From there, you can review them. We\&#x27;ve made it easy to assign feedback to runs and mark them as correct or incorrect directly in the web app, displaying aggregate statistics for each test project.We also make it easier to evaluate these runs. To that end, we\&#x27;ve added a set of evaluators to the open-source LangChain library. These evaluators can be specified when initiating a test run and will evaluate the results once the test run completes. If we’re being honest, most of these evaluators aren\&#x27;t perfect. We would not recommend that you trust them blindly. However, we do think they are useful for guiding your eye to examples you should look at. This becomes especially valuable as the number of data points increases and it becomes infeasible to look at each one manually.Human Evaluation\u200bAutomatic evaluation metrics are helpful for getting consistent and scalable information about model behavior;\nhowever, there is still no complete substitute for human review to get the utmost quality and reliability from your application.\nLangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like creativity or humorTo sample and validate a subset of runs that were auto-evaluated, ensuring the automatic metrics are still reliable and capturing the right informationAll the annotations made using the queue are assigned as &quot;feedback&quot; to the source runs, so you can easily filter and analyze them later.&#x27;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;), Document(page_content=&quot;You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.We’ve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing — mirroring the debug mode approach.We’ve provided several examples in the LangSmith documentation for extracting insights from logged runs. In addition to guiding you on performing this task yourself, we also provide examples of integrating with third parties for this purpose. We&#x27;re eager to expand this area in the coming months! If you have ideas for either -- an open-source way to evaluate, or are building a company that wants to do analytics over these runs, please reach out.Exporting datasets\u200bLangSmith makes it easy to curate datasets. However, these aren’t just useful inside LangSmith; they can be exported for use in other contexts. Notable applications include exporting for use in OpenAI Evals or fine-tuning, such as with FireworksAI.To set up tracing in Deno, web browsers, or other runtime environments without access to the environment, check out the FAQs.↩PreviousLangSmithNextTracingOn by defaultDebuggingWhat was the exact input to the LLM?If I edit the prompt, how does that affect the output?What is the exact sequence of events?Why did my chain take much longer than expected?How many tokens were used?Collaborative debuggingCollecting examplesTesting &amp; evaluationHuman EvaluationMonitoringExporting datasetsCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.&quot;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;)]</span></span><br><span class="line">转换成向量完毕</span><br><span class="line">将向量转换为检索器</span><br><span class="line">构建问题完毕</span><br><span class="line">开始调用</span><br><span class="line">调用完毕</span><br><span class="line">&#123;<span class="comment">&#x27;input&#x27;: &#x27;how can langsmith help with testing?&#x27;, &#x27;context&#x27;: [Document(page_content=&quot;You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.We’ve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing — mirroring the debug mode approach.We’ve provided several examples in the LangSmith documentation for extracting insights from logged runs. In addition to guiding you on performing this task yourself, we also provide examples of integrating with third parties for this purpose. We&#x27;re eager to expand this area in the coming months! If you have ideas for either -- an open-source way to evaluate, or are building a company that wants to do analytics over these runs, please reach out.Exporting datasets\u200bLangSmith makes it easy to curate datasets. However, these aren’t just useful inside LangSmith; they can be exported for use in other contexts. Notable applications include exporting for use in OpenAI Evals or fine-tuning, such as with FireworksAI.To set up tracing in Deno, web browsers, or other runtime environments without access to the environment, check out the FAQs.↩PreviousLangSmithNextTracingOn by defaultDebuggingWhat was the exact input to the LLM?If I edit the prompt, how does that affect the output?What is the exact sequence of events?Why did my chain take much longer than expected?How many tokens were used?Collaborative debuggingCollecting examplesTesting &amp; evaluationHuman EvaluationMonitoringExporting datasetsCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.&quot;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;), Document(page_content=&#x27;inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat we’ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies\ndataset uploading.Once we have a dataset, how can we use it to test changes to a prompt or chain? The most basic approach is to run the chain over the data points and visualize the outputs. Despite technological advancements, there still is no substitute for looking at outputs by eye. Currently, running the chain over the data points needs to be done client-side. The LangSmith client makes it easy to pull down a dataset and then run a chain over them, logging the results to a new project associated with the dataset. From there, you can review them. We\&#x27;ve made it easy to assign feedback to runs and mark them as correct or incorrect directly in the web app, displaying aggregate statistics for each test project.We also make it easier to evaluate these runs. To that end, we\&#x27;ve added a set of evaluators to the open-source LangChain library. These evaluators can be specified when initiating a test run and will evaluate the results once the test run completes. If we’re being honest, most of these evaluators aren\&#x27;t perfect. We would not recommend that you trust them blindly. However, we do think they are useful for guiding your eye to examples you should look at. This becomes especially valuable as the number of data points increases and it becomes infeasible to look at each one manually.Human Evaluation\u200bAutomatic evaluation metrics are helpful for getting consistent and scalable information about model behavior;\nhowever, there is still no complete substitute for human review to get the utmost quality and reliability from your application.\nLangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like creativity or humorTo sample and validate a subset of runs that were auto-evaluated, ensuring the automatic metrics are still reliable and capturing the right informationAll the annotations made using the queue are assigned as &quot;feedback&quot; to the source runs, so you can easily filter and analyze them later.&#x27;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;), Document(page_content=&#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;), Document(page_content=&quot;retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being made? In what order? What are the inputs and outputs of each call?LangSmith&#x27;s built-in tracing feature offers a visualization to clarify these sequences. This tool is invaluable for understanding intricate and lengthy chains and agents. For chains, it can shed light on the sequence of calls and how they interact. For agents, where the sequence of calls is non-deterministic, it helps visualize the specific sequence for a given run -- something that is impossible to know ahead of time.Why did my chain take much longer than expected?\u200bIf a chain takes longer than expected, you need to identify the cause. By tracking the latency of each step, LangSmith lets you identify and possibly eliminate the slowest components.How many tokens were used?\u200bBuilding and prototyping LLM applications can be expensive. LangSmith tracks the total token usage for a chain and the token usage of each step. This makes it easy to identify potentially costly parts of the chain.Collaborative debugging\u200bIn the past, sharing a faulty chain with a colleague for debugging was challenging when performed locally. With LangSmith, we&#x27;ve added a “Share” button that makes the chain and LLM runs accessible to anyone with the shared link.Collecting examples\u200bMost of the time we go to debug, it&#x27;s because something bad or unexpected outcome has happened in our application. These failures are valuable data points! By identifying how our chain can fail and monitoring these failures, we can test future chain versions against these known issues.Why is this so impactful? When building LLM applications, it’s often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you&#x27;re wandering blind. You don’t have any examples to benchmark your changes against.LangSmith addresses this problem by including an “Add to Dataset” button for each run, making it easy to add the input/output examples a chosen dataset. You can edit the example before adding them to the dataset to include the expected result, which is particularly useful for bad examples.This feature is available at every step of a nested chain, enabling you to add examples for an end-to-end chain, an intermediary chain (such as a LLM Chain), or simply the LLM or Chat Model.End-to-end chain examples are excellent for testing the overall flow, while single, modular LLM Chain or LLM/Chat Model examples can be beneficial for testing the simplest and most directly modifiable components.Testing &amp; evaluation\u200bInitially, we do most of our evaluation manually and ad hoc. We pass in different&quot;, metadata=&#123;&#x27;source&#x27;: &#x27;https://docs.smith.langchain.com/overview&#x27;, &#x27;title&#x27;: &#x27;LangSmith Overview and User Guide | 🦜️🛠️ LangSmith&#x27;, &#x27;description&#x27;: &#x27;Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.&#x27;, &#x27;language&#x27;: &#x27;en&#x27;&#125;)], &#x27;answer&#x27;: &#x27;LangSmith can assist with testing by providing various features to simplify dataset uploading, running chains over the data points, visualizing the outputs, and evaluating the results. Here are some ways LangSmith can help with testing:\n\n1. Easy dataset uploading: LangSmith simplifies dataset uploading, making it easier to construct a small dataset by hand or use an existing one.\n2. Running chains over data points: Once you have a dataset, LangSmith allows you to run the chain over the data points and visualize the outputs. You can review the outputs directly in the web app by assigning feedback to runs and marking them as correct or incorrect.\n3. Evaluating results: LangSmith adds a set of evaluators to the open-source LangChain library, which can be specified when initiating a test run. These evaluators will evaluate the results once the test run completes, providing valuable information for guiding your eye to examples you should look at.\n4. Manual testing and annotation: LangSmith makes it easy to manually review and annotate runs through a visualization of the sequence of events, helping identify subjective qualities that automatic evaluators struggle with.\n5. Tracking token usage: LangSmith tracks the total token usage for a chain and the token usage of each step, making it easier to identify potentially costly parts of the chain.\n6. Collecting examples: LangSmith includes an &quot;Add to Dataset&quot; button for each run, enabling you to add examples for an end-to-end chain, an intermediary chain (such as a LLM Chain), or simply the LLM or Chat Model. This feature is available at every step of a nested chain, making it easier to test the overall flow and individual components.\n\nBy leveraging these features, LangSmith can help streamline your testing process and provide valuable insights into your LLM application\&#x27;s performance.&#x27;&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="Conversation-Retrieval-Chain（对话检索链）">Conversation Retrieval Chain（对话检索链）</h2>
<ul>
<li>我们刚刚创建的链只能回答单一的问题，但有些应用场景需要构建对话型的聊天机器人。</li>
<li>为了实现这一点，我们仍然可以使用create_retrieval_chain函数，但是我们需要改变两件事：
<ul>
<li>检索方法现在不应仅适用于最近的输入，而应考虑整个历史记录。</li>
<li>最终的 LLM 链同样应该考虑整个历史<br>
更新检索（retrieval）<br>
我们创建了一个新的链，这个链将接受最近的用户输入（input）和整个对话历史（chat_history），然后使用语言模型生成一个搜索查询。这里使用了 create_history_aware_retriever 函数来实现这个新链。</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> create_history_aware_retriever</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> MessagesPlaceholder</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个提示模板，用于根据对话历史生成搜索查询</span></span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    MessagesPlaceholder(variable_name=<span class="string">&quot;chat_history&quot;</span>),  <span class="comment"># 对话历史的占位符</span></span><br><span class="line">    (<span class="string">&quot;user&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),  <span class="comment"># 用户输入的占位符</span></span><br><span class="line">    (<span class="string">&quot;user&quot;</span>, <span class="string">&quot;在上述对话的基础上，生成一个搜索查询，以获取与对话相关的信息&quot;</span>)  <span class="comment"># 生成搜索查询的指令，基于对话内容</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个检索器链，整合语言模型、检索器和定义的提示</span></span><br><span class="line">retriever_chain = create_history_aware_retriever(llm, retriever, prompt)</span><br></pre></td></tr></table></figure>
<ul>
<li>我们可以传入后续的问题实例来测试这一点</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, AIMessage</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义对话历史，包括人类消息和AI消息</span></span><br><span class="line">chat_history = [HumanMessage(content=<span class="string">&quot;LangSmith可以帮助我测试App吗？&quot;</span>), AIMessage(content=<span class="string">&quot;Yes!&quot;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用检索器链，传入对话历史和用户输入</span></span><br><span class="line">retriever_chain.invoke(&#123;</span><br><span class="line">    <span class="string">&quot;chat_history&quot;</span>: chat_history,</span><br><span class="line">    <span class="string">&quot;input&quot;</span>: <span class="string">&quot;告诉我怎么做&quot;</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li>此时的输出应该是会返回有关 LangSmith 中测试的文档。这是因为LLM生成了一个新查询，将聊天历史记录与后续问题相结合。</li>
<li>现在我们有了这个新的检索器，我们可以创建一个新的链来继续与这些检索到的文档进行对话。</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">prompt</span> = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;根据上下文回答用户的问题\n\n&#123;context&#125;&quot;</span>),</span><br><span class="line">    MessagesPlaceholder(variable_name=<span class="string">&quot;chat_history&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;user&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="attr">document_chain</span> = create_stuff_documents_chain(llm, prompt)</span><br><span class="line"><span class="attr">retrieval_chain</span> = create_retrieval_chain(retriever_chain, document_chain)</span><br></pre></td></tr></table></figure>
<ul>
<li>现在进行整体的测试：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">chat_history = [HumanMessage(content=<span class="string">&quot;LangSmith可以帮助我测试App吗？&quot;</span>), AIMessage(content=<span class="string">&quot;Yes!&quot;</span>)]</span><br><span class="line"></span><br><span class="line">retriever_chain.invoke(&#123;</span><br><span class="line">    <span class="string">&quot;chat_history&quot;</span>: chat_history,</span><br><span class="line">    <span class="string">&quot;input&quot;</span>: <span class="string">&quot;告诉我怎么做&quot;</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li>会出了一个连贯的答案，表明我们已经成功地将检索链变成了聊天机器人</li>
</ul>
<h2 id="Agent">Agent</h2>
<ul>
<li>构建代理时要做的第一件事就是决定它应该有权访问哪些工具。在此示例中，我们将为代理提供两个工具的访问权限：
<ol>
<li>我们刚刚创建的检索器。这将让它轻松回答有关 LangSmith 的问题</li>
</ol>
<ul>
<li>首先，让我们为刚刚创建的检索器设置一个工具：</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.tools.retriever <span class="keyword">import</span> create_retriever_tool</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个检索器就是刚刚爬取LongSmith文档的内容，生成的检索器</span></span><br><span class="line">retriever_tool = create_retriever_tool(</span><br><span class="line">    retriever,</span><br><span class="line">    <span class="string">&quot;langsmith_search&quot;</span>,</span><br><span class="line">    <span class="string">&quot;搜索有关LangSmith的信息或者有关LangSmith的任何问题，必须使用这个工具！&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>一个搜索工具。这将使它能够轻松回答需要最新信息的问题。<br>
- 官网示例中使用的搜索工具是Tavily，需要一个 API 密钥（有免费套餐）。在他们的平台上创建后，需要将其设置为环境变量</li>
</ol>
<pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"></span><br><span class="line">search = TavilySearchResults()</span><br></pre></td></tr></table></figure>
- 我们现在可以创建我们想要使用的工具的列表：
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tools = [retriever_tool, search]</span><br></pre></td></tr></table></figure>
- 现在我们有了工具，我们可以创建一个代理来使用它们。
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这个可以拉取预定义好的prompt</span></span><br><span class="line">pip install langchainhub</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> hub</span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> create_openai_functions_agent</span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> AgentExecutor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拉取别人预定义好的prompt</span></span><br><span class="line">prompt = hub.pull(<span class="string">&quot;hwchase17/openai-functions-agent&quot;</span>)</span><br><span class="line">llm = ChatOpenAI(model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">agent = create_openai_functions_agent(llm, tools, prompt)</span><br><span class="line">agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
- 调用
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">agent_executor.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;LangSmith可以帮助我测试App吗？&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>
</code></pre>
<h2 id="构建服务">构建服务</h2>
<ul>
<li>LangServe 可以帮助开发人员将 LangChain 链部署为 REST API。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> WebBaseLoader</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain.tools.retriever <span class="keyword">import</span> create_retriever_tool</span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> hub</span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> create_openai_functions_agent</span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> AgentExecutor</span><br><span class="line"><span class="keyword">from</span> langchain.pydantic_v1 <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> BaseMessage</span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> add_routes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 加载检索器（Retriever）</span></span><br><span class="line"><span class="comment"># 首先，通过 WebBaseLoader 从 LangChain 文档网站加载文档数据。然后，使用 RecursiveCharacterTextSplitter 将文档分割为文档片段，并使用 OpenAIEmbeddings 将文档片段嵌入为向量。最后，使用 FAISS 创建一个向量存储作为检索器。</span></span><br><span class="line">loader = WebBaseLoader(<span class="string">&quot;https://docs.smith.langchain.com/overview&quot;</span>)</span><br><span class="line">docs = loader.load()</span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter()</span><br><span class="line">documents = text_splitter.split_documents(docs)</span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line">vector = FAISS.from_documents(documents, embeddings)</span><br><span class="line">retriever = vector.as_retriever()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建工具（Tools）</span></span><br><span class="line"><span class="comment"># 创建两个工具：一个是之前创建的检索器工具 retriever_tool，另一个是 Tavily 搜索工具 search。</span></span><br><span class="line">retriever_tool = create_retriever_tool(</span><br><span class="line">    retriever,</span><br><span class="line">    <span class="string">&quot;langsmith_search&quot;</span>,</span><br><span class="line">    <span class="string">&quot;搜索有关LangSmith的信息或者有关LangSmith的任何问题，必须使用这个工具！&quot;</span>,</span><br><span class="line">)</span><br><span class="line">search = TavilySearchResults()</span><br><span class="line">tools = [retriever_tool, search]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 创建代理</span></span><br><span class="line"><span class="comment"># 使用 LangChain Hub 中提供的预定义提示（自己构建也可以），创建一个使用 OpenAI 模型和工具的代理。这个代理被设置为能够决定在处理问题时使用哪些工具。</span></span><br><span class="line">prompt = hub.pull(<span class="string">&quot;hwchase17/openai-functions-agent&quot;</span>)</span><br><span class="line">llm = ChatOpenAI(model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">agent = create_openai_functions_agent(llm, tools, prompt)</span><br><span class="line">agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. FastAPI 定义</span></span><br><span class="line">app = FastAPI(</span><br><span class="line">  title=<span class="string">&quot;LangChain Server&quot;</span>,</span><br><span class="line">  version=<span class="string">&quot;1.0&quot;</span>,</span><br><span class="line">  description=<span class="string">&quot;A simple API server using LangChain&#x27;s Runnable interfaces&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 添加链路由</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过调用 add_routes 函数，将代理链添加为 FastAPI 应用的一个路由，从而可以通过 /agent 路径访问代理链。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Input</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">input</span>: <span class="built_in">str</span></span><br><span class="line">    chat_history: <span class="type">List</span>[BaseMessage] = Field(</span><br><span class="line">        ...,</span><br><span class="line">        extra=&#123;<span class="string">&quot;widget&quot;</span>: &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;chat&quot;</span>, <span class="string">&quot;input&quot;</span>: <span class="string">&quot;location&quot;</span>&#125;&#125;,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Output</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    output: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line">add_routes(</span><br><span class="line">    app,</span><br><span class="line">    agent_executor.with_types(input_type=Input, output_type=Output),</span><br><span class="line">    path=<span class="string">&quot;/agent&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;localhost&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>
<h1>链的概念（补充）</h1>
<ul>
<li>链（Chains）通常将大语言模型（LLM）与提示（Prompt）结合在一起，基于此，我们可以对文本或数据进行一系列操作。链（Chains）可以一次性接受多个输入。例如，我们可以创建一个链，该链接受用户输入，使用提示模板对其进行格式化，然后将格式化的响应传递给 LLM 。我们可以通过将多个链组合在一起，或者通过将链与其他组件组合在一起来构建更复杂的链。</li>
</ul>
<h2 id="顺序链（SequentialChains）">顺序链（SequentialChains）</h2>
<ul>
<li>是按预定义顺序执行其链接的链。具体来说，我们将使用简单顺序链（SimpleSequentialChain），这是顺序链的最简单类型，其中每个步骤都有一个输入/输出，一个步骤的输出是下一个步骤的输入。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Tongyi</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain, SimpleSequentialChain</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;DASHSCOPE_API_KEY&quot;</span>] = <span class="string">&quot;sk-1903ddb520ac4637a1d36b2f93e0aa4c&quot;</span></span><br><span class="line"></span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line">prompt1 = ChatPromptTemplate.from_template(<span class="string">&quot;你现在是写作领域的大师，现在为&#123;title&#125;这篇文章生成一些大纲吧。&quot;</span>)</span><br><span class="line"></span><br><span class="line">chain_one = LLMChain(llm=llm, prompt=prompt1)</span><br><span class="line"></span><br><span class="line">prompt2 = ChatPromptTemplate.from_template(<span class="string">&quot;根据这个大纲：&#123;toc&#125;，生成每个章节对应的内容吧。&quot;</span>)</span><br><span class="line"></span><br><span class="line">chain_two = LLMChain(llm=llm, prompt=prompt2)</span><br><span class="line"></span><br><span class="line">chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    title = <span class="built_in">input</span>(<span class="string">&quot;请输入题目：&quot;</span>)</span><br><span class="line">    res = chain.invoke(&#123;<span class="string">&quot;input&quot;</span>: title&#125;)</span><br><span class="line">    <span class="built_in">print</span>(json.dumps(res, indent=<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<ul>
<li>执行结果</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">当然可以，以下是一个关于“大学生网红消费行为分析”的文章大纲：</span><br><span class="line"></span><br><span class="line">I. 引言</span><br><span class="line">   A. 网红经济的崛起与大学生消费者的概述</span><br><span class="line">   B. 大学生网红消费现象的重要性及研究背景</span><br><span class="line">   C. 文章的研究目的和意义</span><br><span class="line"></span><br><span class="line">II. 大学生网红消费者群体特征分析</span><br><span class="line">   A. 年龄、性别、专业等人口统计学特征</span><br><span class="line">   B. 大学生的网络使用习惯与社交媒体偏好</span><br><span class="line">   C. 大学生对网红的认可度与信任度</span><br><span class="line"></span><br><span class="line">III. 大学生网红消费行为的特点</span><br><span class="line">   A. 消费动机：从娱乐消遣到购物决策的影响</span><br><span class="line">   B. 消费品类偏向：时尚穿搭、美妆护肤、电子产品等方面的消费情况</span><br><span class="line">   C. 跟风消费与个性化消费需求的平衡</span><br><span class="line">   D. 情感因素在购买决策中的作用</span><br><span class="line"></span><br><span class="line">IV. 网红对大学生消费行为的影响机制</span><br><span class="line">   A. 网红的影响力来源：内容创作能力、人格魅力、口碑效应等</span><br><span class="line">   B. 网红营销策略对大学生消费心理的影响：情感共鸣、生活方式塑造、意见领袖角色</span><br><span class="line">   C. 网红广告与软性推广对大学生消费选择的引导</span><br><span class="line"></span><br><span class="line">V. 大学生网红消费行为的社会文化影响</span><br><span class="line">   A. 对大学生价值观塑造的影响</span><br><span class="line">   B. 社会审美趋势与消费观念的变化</span><br><span class="line">   C. 对校园文化和市场经济发展的启示</span><br><span class="line"></span><br><span class="line">VI. 结论</span><br><span class="line">   A. 大学生网红消费行为的主要特点及其成因总结</span><br><span class="line">   B. 对教育部门、企业、网红自身以及社会各方面应对大学生网红消费行为进行合理引导和规范的建议</span><br><span class="line">   C. 展望未来研究方向与可能性</span><br><span class="line"></span><br><span class="line">这个大纲旨在全面探讨大学生网红消费行为的现象、特点、成因以及其背后的社会文化影响，并针对相关各方提出有针对性的思考与建议。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面就是每个章节对应的内容</span></span><br><span class="line"></span><br><span class="line">I. 引言</span><br><span class="line">A. 网红经济的崛起与大学生消费者的概述</span><br><span class="line">随着互联网技术的发展和社交媒体平台的普及，网红经济作为一种新型商业模式在全球范围内迅速崛起。大学生作为网络主力军和新兴消费群体，他们对于网红的追捧和消费行为成为当前市场关注的热点。这一现象不仅反映出了网红经济的巨大潜力，也揭示了大学生在消费观念和行为上的新变化。</span><br><span class="line"></span><br><span class="line">B. 大学生网红消费现象的重要性及研究背景</span><br><span class="line">大学生网红消费现象日益普遍，其背后的消费心理、消费行为模式以及对社会文化的影响具有重要研究价值。通过深入探究这一现象，有助于理解新一代消费者的消费趋势，为相关企业和政策制定者提供针对性的策略指导。</span><br><span class="line"></span><br><span class="line">C. 文章的研究目的和意义</span><br><span class="line">本文旨在通过系统地研究大学生网红消费行为，揭示其特征、成因及其社会文化影响，为教育部门、企业、网红自身乃至整个社会提供理性应对这一现象的思路和建议，同时对未来相关研究领域的发展方向进行展望。</span><br><span class="line"></span><br><span class="line">II. 大学生网红消费者群体特征分析</span><br><span class="line">A. 年龄、性别、专业等人口统计学特征</span><br><span class="line">以在校大学生为主体的年轻消费人群主要集中在<span class="number">18</span>-<span class="number">24</span>岁年龄段，男女比例相对均衡，不同专业的学生可能由于兴趣爱好、审美取向等因素，在网红消费上表现出一定的差异。</span><br><span class="line"></span><br><span class="line">B. 大学生的网络使用习惯与社交媒体偏好</span><br><span class="line">当代大学生是互联网的重度使用者，他们在日常生活中广泛依赖于社交媒体平台获取信息、交流互动和娱乐休闲。尤其偏爱短视频、直播、微博等新媒体形式，这为网红传播内容提供了广阔的受众基础。</span><br><span class="line"></span><br><span class="line">C. 大学生对网红的认可度与信任度</span><br><span class="line">大学生普遍认为网红具备较高的潮流引领力和社交影响力，对于具有一定专业素养和亲和力的网红更容易产生认同感和信赖感，从而将其推荐的产品或服务纳入自己的消费考虑范围。</span><br><span class="line"></span><br><span class="line">III. 大学生网红消费行为的特点</span><br><span class="line">A. 消费动机：从娱乐消遣到购物决策的影响</span><br><span class="line">大学生在关注网红的过程中，最初可能出于娱乐消遣的需求，但逐渐地，网红所展示的生活方式、时尚品味以及产品体验等内容会影响他们的购物决策，使得消费行为由单纯的观赏转变为实际购买行为。</span><br><span class="line"></span><br><span class="line">B. 消费品类偏向：时尚穿搭、美妆护肤、电子产品等方面的消费情况</span><br><span class="line">大学生网红消费行为中，时尚穿搭、美妆护肤和个人电子产品是最常见的消费类别。这些商品往往与年轻人追求个性化、时尚化和高品质生活的需求相契合。</span><br><span class="line"></span><br><span class="line">C. 跟风消费与个性化消费需求的平衡</span><br><span class="line">大学生在网红消费过程中，既存在跟风模仿的现象，也注重个性表达和自我风格的塑造。他们会在一定程度上接受网红推荐的商品和服务，同时也根据个人喜好和实际情况做出选择，实现跟风与个性需求的动态平衡。</span><br><span class="line"></span><br><span class="line">D. 情感因素在购买决策中的作用</span><br><span class="line">大学生消费者在网红购物决策中情感因素占据较大比重，包括对网红本人的情感认同、对网红所构建生活方式的向往以及与其他粉丝间的社交关系等因素都会影响到购买行为。</span><br><span class="line"></span><br><span class="line">IV. 网红对大学生消费行为的影响机制</span><br><span class="line">A. 网红的影响力来源：内容创作能力、人格魅力、口碑效应等</span><br><span class="line">网红的影响力源于其独特的内容创作能力、鲜明的个性特质以及良好的口碑效应。他们通过高质量的内容输出，吸引并维系粉丝群体，进而转化为商业价值。</span><br><span class="line"></span><br><span class="line">B. 网红营销策略对大学生消费心理的影响：情感共鸣、生活方式塑造、意见领袖角色</span><br><span class="line">网红运用情感共鸣、生活方式展示以及意见领袖的角色定位，巧妙地将产品融入其中，激发大学生消费者的心理共鸣，形成潜在购买意愿，并推动实际消费行为的发生。</span><br><span class="line"></span><br><span class="line">C. 网红广告与软性推广对大学生消费选择的引导</span><br><span class="line">网红借助广告植入、品牌合作等形式进行商品推广，这种隐性且易于接受的营销手段在很大程度上左右了大学生的消费选择。</span><br><span class="line"></span><br><span class="line">V. 大学生网红消费行为的社会文化影响</span><br><span class="line">A. 对大学生价值观塑造的影响</span><br><span class="line">大学生网红消费行为促进了他们对美的追求、个性化意识的觉醒以及对品质生活的向往，进一步塑造了新一代消费者的消费价值观。</span><br><span class="line"></span><br><span class="line">B. 社会审美趋势与消费观念的变化</span><br><span class="line">随着大学生对网红消费的积极参与，他们的审美情趣和消费观念逐渐成为社会审美趋势的重要组成部分，进一步推动着社会整体消费观念的变革与发展。</span><br><span class="line"></span><br><span class="line">C. 对校园文化和市场经济发展的启示</span><br><span class="line">大学生网红消费行为不仅反映了当前市场经济环境下消费结构和消费行为的新变化，也为校园文化的多元化发展提供了新的视角与启示。</span><br><span class="line"></span><br><span class="line">VI. 结论</span><br><span class="line">A. 大学生网红消费行为的主要特点及其成因总结</span><br><span class="line">通过对大学生网红消费行为的研究，我们发现其主要特点包括高度活跃的社交媒体参与、强烈的情感驱动消费、紧跟潮流且兼顾个性化的消费需求以及深受网红营销策略的影响。这些特点的背后成因主要包括大学生独特的年龄特征、网络环境下的信息接收方式以及网红影响力的多重作用。</span><br><span class="line"></span><br><span class="line">B. 对教育部门、企业、网红自身以及社会各方面应对大学生网红消费行为进行合理引导和规范的建议</span><br><span class="line">教育部门应加强对大学生消费观的引导教育，培养他们的理性消费意识；企业应充分认识到网红营销的价值，合理利用网红资源，同时严格遵守相关法律法规，确保营销活动的合法合规；网红自身则需保持职业操守，传递正能量，发挥好榜样作用；社会各界也应对网红经济持开放包容态度，强化监管与自律相结合，共同营造健康有序的网红消费环境。</span><br><span class="line"></span><br><span class="line">C. 展望未来研究方向与可能性</span><br><span class="line">未来的研究可以从更微观的层面深入剖析大学生网红消费行为的内在机理，探究不同个体之间消费差异的具体原因；也可以着眼于全球视野，对比国内外大学生网红消费现象的异同和发展趋势；此外，还可以探讨如何结合新技术应用，如大数据、人工智能等，更好地理解和引导大学生网红消费行为。</span><br></pre></td></tr></table></figure>
<h2 id="多链组合">多链组合</h2>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains import LLMChain, SequentialChain</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms.tongyi import Tongyi</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts import ChatPromptTemplate</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;DASHSCOPE_API_KEY&quot;</span>] = <span class="string">&quot;sk-1903ddb520ac4637a1d36b2f93e0aa4c&quot;</span></span><br><span class="line"></span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子链1</span></span><br><span class="line"><span class="comment"># prompt模板 1: 翻译成英语（把下面的review翻译成英语）</span></span><br><span class="line">first_prompt = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;把下面的评论review翻译成中文:&quot;</span></span><br><span class="line">    <span class="string">&quot;\n\n&#123;Review&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># chain 1: 输入：Review    输出：中文的 Review</span></span><br><span class="line">chain_one = LLMChain(<span class="attribute">llm</span>=llm, <span class="attribute">prompt</span>=first_prompt, <span class="attribute">output_key</span>=<span class="string">&quot;Chinese_Review&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子链2</span></span><br><span class="line"><span class="comment"># prompt模板 2: 用一句话总结下面的 review</span></span><br><span class="line">second_prompt = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;请你用一句话来总结下面的评论review:&quot;</span></span><br><span class="line">    <span class="string">&quot;\n\n&#123;Chinese_Review&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># chain 2: 输入：中文的Review   输出：总结</span></span><br><span class="line">chain_two = LLMChain(<span class="attribute">llm</span>=llm, <span class="attribute">prompt</span>=second_prompt, <span class="attribute">output_key</span>=<span class="string">&quot;summary&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子链3</span></span><br><span class="line"><span class="comment"># prompt模板 3: 下面review使用的什么语言</span></span><br><span class="line">third_prompt = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;下面的评论review使用的什么语言:\n\n&#123;Review&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># chain 3: 输入：Review  输出：语言</span></span><br><span class="line">chain_three = LLMChain(<span class="attribute">llm</span>=llm, <span class="attribute">prompt</span>=third_prompt, <span class="attribute">output_key</span>=<span class="string">&quot;language&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子链4</span></span><br><span class="line"><span class="comment"># prompt模板 4: 使用特定的语言对下面的总结写一个后续回复</span></span><br><span class="line">fourth_prompt = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;使用特定的语言对下面的总结写一个后续回复:&quot;</span></span><br><span class="line">    <span class="string">&quot;\n\n总结: &#123;summary&#125;\n\n语言: &#123;language&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># chain 4: 输入： 总结, 语言    输出： 后续回复</span></span><br><span class="line">chain_four = LLMChain(<span class="attribute">llm</span>=llm, <span class="attribute">prompt</span>=fourth_prompt, <span class="attribute">output_key</span>=<span class="string">&quot;followup_message&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入：review</span></span><br><span class="line"><span class="comment">#输出：中文review，总结，后续回复</span></span><br><span class="line">overall_chain = SequentialChain(</span><br><span class="line">    chains=[chain_one, chain_two, chain_three, chain_four],</span><br><span class="line">    input_variables=[<span class="string">&quot;Review&quot;</span>],</span><br><span class="line">    output_variables=[<span class="string">&quot;Chinese_Review&quot;</span>, <span class="string">&quot;summary&quot;</span>, <span class="string">&quot;followup_message&quot;</span>, <span class="string">&quot;language&quot;</span>],</span><br><span class="line">    <span class="attribute">verbose</span>=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    text = input(<span class="string">&quot;请输入内容：&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(overall_chain.invoke(&#123;<span class="string">&quot;Review&quot;</span>: text&#125;))</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s11.ax1x.com/2024/02/24/pFUftjf.png" alt=""></p>
<h2 id="路由链">路由链</h2>
<ul>
<li>前面的链的输入顺序基本上都是固定的，如果想做更复杂的事情，就需要根据输入将其路由到特定的链。假设你有多个子链，每个子链都专门用于特定类型的输入，那么可以组成一个路由链</li>
<li>路由器由两个组件组成：
<ol>
<li>路由链（Router Chain）：路由器链本身，负责选择要调用的下一个链</li>
<li>destination_chains：路由器链可以路由到的链</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain, MultiPromptChain</span><br><span class="line"><span class="keyword">from</span> langchain.chains.router.llm_router <span class="keyword">import</span> RouterOutputParser, LLMRouterChain</span><br><span class="line"><span class="keyword">from</span> langchain.chains.router.multi_prompt_prompt <span class="keyword">import</span> MULTI_PROMPT_ROUTER_TEMPLATE</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms.tongyi <span class="keyword">import</span> Tongyi</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, PromptTemplate</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;DASHSCOPE_API_KEY&quot;</span>] = <span class="string">&quot;sk-1903ddb520ac4637a1d36b2f93e0aa4c&quot;</span></span><br><span class="line"></span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义多种提示模板</span></span><br><span class="line"><span class="comment"># 第一个提示适合回答物理问题</span></span><br><span class="line">physics_template = <span class="string">&quot;&quot;&quot;你是一个非常聪明的物理专家。 \</span></span><br><span class="line"><span class="string">你擅长用一种简洁并且易于理解的方式去回答问题。\</span></span><br><span class="line"><span class="string">当你不知道问题的答案时，你承认\</span></span><br><span class="line"><span class="string">你不知道.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">这是一个问题:</span></span><br><span class="line"><span class="string">&#123;input&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二个提示适合回答数学问题</span></span><br><span class="line">math_template = <span class="string">&quot;&quot;&quot;你是一个非常优秀的数学家。 \</span></span><br><span class="line"><span class="string">你擅长回答数学问题。 \</span></span><br><span class="line"><span class="string">你之所以如此优秀， \</span></span><br><span class="line"><span class="string">是因为你能够将棘手的问题分解为组成部分，\</span></span><br><span class="line"><span class="string">回答组成部分，然后将它们组合在一起，回答更广泛的问题。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">这是一个问题：</span></span><br><span class="line"><span class="string">&#123;input&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三个适合回答历史问题</span></span><br><span class="line">history_template = <span class="string">&quot;&quot;&quot;你是以为非常优秀的历史学家。 \</span></span><br><span class="line"><span class="string">你对一系列历史时期的人物、事件和背景有着极好的学识和理解\</span></span><br><span class="line"><span class="string">你有能力思考、反思、辩证、讨论和评估过去。\</span></span><br><span class="line"><span class="string">你尊重历史证据，并有能力利用它来支持你的解释和判断。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">这是一个问题:</span></span><br><span class="line"><span class="string">&#123;input&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第四个适合回答计算机问题</span></span><br><span class="line">computerscience_template = <span class="string">&quot;&quot;&quot; 你是一个成功的计算机科学专家。\</span></span><br><span class="line"><span class="string">你有创造力、协作精神、\</span></span><br><span class="line"><span class="string">前瞻性思维、自信、解决问题的能力、\</span></span><br><span class="line"><span class="string">对理论和算法的理解以及出色的沟通技巧。\</span></span><br><span class="line"><span class="string">你非常擅长回答编程问题。\</span></span><br><span class="line"><span class="string">你之所以如此优秀，是因为你知道  \</span></span><br><span class="line"><span class="string">如何通过以机器可以轻松解释的命令式步骤描述解决方案来解决问题，\</span></span><br><span class="line"><span class="string">并且你知道如何选择在时间复杂性和空间复杂性之间取得良好平衡的解决方案。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">这还是一个问题：</span></span><br><span class="line"><span class="string">&#123;input&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为每个模板命名，并且给出具体描述，将这些信息传递给路由链，路由链决定何时调用子链</span></span><br><span class="line">prompt_infos = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;名字&quot;</span>: <span class="string">&quot;物理学&quot;</span>,</span><br><span class="line">        <span class="string">&quot;描述&quot;</span>: <span class="string">&quot;擅长回答关于物理学的问题&quot;</span>,</span><br><span class="line">        <span class="string">&quot;提示模板&quot;</span>: physics_template</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;名字&quot;</span>: <span class="string">&quot;数学&quot;</span>,</span><br><span class="line">        <span class="string">&quot;描述&quot;</span>: <span class="string">&quot;擅长回答数学问题&quot;</span>,</span><br><span class="line">        <span class="string">&quot;提示模板&quot;</span>: math_template</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;名字&quot;</span>: <span class="string">&quot;历史&quot;</span>,</span><br><span class="line">        <span class="string">&quot;描述&quot;</span>: <span class="string">&quot;擅长回答历史问题&quot;</span>,</span><br><span class="line">        <span class="string">&quot;提示模板&quot;</span>: history_template</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;名字&quot;</span>: <span class="string">&quot;计算机科学&quot;</span>,</span><br><span class="line">        <span class="string">&quot;描述&quot;</span>: <span class="string">&quot;擅长回答计算机科学问题&quot;</span>,</span><br><span class="line">        <span class="string">&quot;提示模板&quot;</span>: computerscience_template</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于提示模版信息创建相应目标链</span></span><br><span class="line">destination_chains = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> p_info <span class="keyword">in</span> prompt_infos:</span><br><span class="line">    name = p_info[<span class="string">&quot;名字&quot;</span>]</span><br><span class="line">    prompt_template = p_info[<span class="string">&quot;提示模板&quot;</span>]</span><br><span class="line">    prompt = ChatPromptTemplate.from_template(template=prompt_template)</span><br><span class="line">    chain = LLMChain(llm=llm, prompt=prompt)</span><br><span class="line">    destination_chains[name] = chain</span><br><span class="line"></span><br><span class="line">destinations = [<span class="string">f&quot;<span class="subst">&#123;p[<span class="string">&#x27;名字&#x27;</span>]&#125;</span>: <span class="subst">&#123;p[<span class="string">&#x27;描述&#x27;</span>]&#125;</span>&quot;</span> <span class="keyword">for</span> p <span class="keyword">in</span> prompt_infos]</span><br><span class="line">destinations_str = <span class="string">&quot;\n&quot;</span>.join(destinations)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建默认目标链，当路由器无法决定使用哪个子链时调用的链。</span></span><br><span class="line">default_prompt = ChatPromptTemplate.from_template(<span class="string">&quot;&#123;input&#125;&quot;</span>)</span><br><span class="line">default_chain = LLMChain(llm=llm, prompt=default_prompt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建路由链</span></span><br><span class="line">router_template = MULTI_PROMPT_ROUTER_TEMPLATE.<span class="built_in">format</span>(destinations=destinations_str)</span><br><span class="line"></span><br><span class="line">router_prompt = PromptTemplate(</span><br><span class="line">    template=router_template,</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    output_parser=RouterOutputParser(),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">router_chain = LLMRouterChain.from_llm(llm, router_prompt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建整体链路</span></span><br><span class="line">chain = MultiPromptChain(router_chain=router_chain,  <span class="comment"># 路由链路</span></span><br><span class="line">                         destination_chains=destination_chains,  <span class="comment"># 目标链路</span></span><br><span class="line">                         default_chain=default_chain,  <span class="comment"># 默认链路</span></span><br><span class="line">                         verbose=<span class="literal">True</span></span><br><span class="line">                         )</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    que = <span class="built_in">input</span>(<span class="string">&quot;请输入问题：&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(chain.invoke(&#123;<span class="string">&quot;input&quot;</span>: que&#125;))</span><br></pre></td></tr></table></figure>
<ul>
<li>后续我们可以预定义非常多的prompt，然后通过路由链来进行任务分发，尽可能把任务细分，这样出现问题时，只需要关注对应的某一个prompt，而不需要整体的改动。</li>
</ul>
<h1>代理的概念（补充）</h1>
<ul>
<li>
<p>大型语言模型（LLMs）非常强大，但它们缺乏“最笨”的计算机程序可以轻松处理的特定能力。LLM 对逻辑推理、计算和检索外部信息的能力较弱，这与最简单的计算机程序形成对比。例如，语言模型无法准确回答简单的计算问题，还有当询问最近发生的事件时，其回答也可能过时或错误，因为无法主动获取最新信息。这是由于当前语言模型仅依赖预训练数据，与外界“断开”。要克服这一缺陷，LangChain框架提出了“代理”(Agent)的解决方案。</p>
</li>
<li>
<p>代理作为语言模型的外部模块，可提供计算、逻辑、检索等功能的支持，使语言模型获得异常强大的推理和获取信息的超能力。</p>
</li>
<li>
<p>要使用代理 (Agents) ，我们需要三样东西：</p>
<ol>
<li>一个基本的 LLM</li>
<li>我们将要进行交互的工具 Tools</li>
<li>一个控制交互的代理 (Agents) 。</li>
</ol>
<ul>
<li>现在尝试使用代理来解决数学问题</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> load_tools, initialize_agent, AgentType</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms.tongyi <span class="keyword">import</span> Tongyi</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;DASHSCOPE_API_KEY&quot;</span>] = <span class="string">&quot;sk-1903ddb520ac4637a1d36b2f93e0aa4c&quot;</span></span><br><span class="line"></span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line">tools = load_tools(</span><br><span class="line">    [<span class="string">&quot;llm-math&quot;</span>, <span class="string">&quot;wikipedia&quot;</span>],</span><br><span class="line">    llm=llm</span><br><span class="line">)</span><br><span class="line">agent = initialize_agent(</span><br><span class="line">    tools,  <span class="comment"># 第二步加载的工具</span></span><br><span class="line">    llm,  <span class="comment"># 第一步初始化的模型</span></span><br><span class="line">    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,  <span class="comment"># 代理类型</span></span><br><span class="line">    handle_parsing_errors=<span class="literal">True</span>,  <span class="comment"># 处理解析错误</span></span><br><span class="line">    verbose=<span class="literal">True</span>  <span class="comment"># 输出中间步骤</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">agent.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;2084的25%是多少？还有，你知道Palworld这款游戏吗&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>输出</p>
<blockquote>
<p>Thought: 第一个问题需要计算2084的25%，可以使用计算器工具；第二个问题询问关于Palworld这款游戏的信息，需要用到Wikipedia工具。</p>
<p>Action:</p>
 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;action&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Calculator&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;action_input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2084 * 25%&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>Observation: Answer: 521.0<br>
Thought:对于第二个问题，我需要使用Wikipedia工具来查询Palworld这款游戏的信息。<br>
Action:</p>
 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;action&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Wikipedia&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;action_input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Palworld&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>Observation: Page: Palworld<br>
Summary: Palworld is an action-adventure survival game by Japanese developer Pocket Pair. The game is set in an open world populated with animal-like creatures known as “Pals”. The players can battle and capture Pals in order to use them for base building, traversal, and combat. Palworld can be played either solo, or online by up to 32 players on one server. Announced in 2021, it was launched via early access for Windows, Xbox One, and Xbox Series X/S in January 2024.<br>
The game’s comedic premise, which involves using firearms and equipping Pals with them, earned it the nickname “Pokémon with guns”. Other elements, such as using creatures for food or placing them to work in mines and factories, have also garnered attention. It was generally well received, with praise for its gameplay, content, and satirical premise, but criticism for its reliance on shock humor and use of unoriginal designs and mechanics.Palworld sold eight million units in the first six days of early access and reached two million concurrent players on Steam, making it the second-highest played game of all time on the platform.</p>
<p>Page: Brotato<br>
Summary: Brotato is a 2023 shoot 'em up video game created by French independent developer Thomas Gervraud under the studio name Blobfish. It was first released via Steam early access in 2022, during which it sold over one million copies. Brotato received positive reviews from critics and players, and it was later ported to multiple platforms.</p>
<p>Page: List of video games in development<br>
Summary: This is a confirmed list of video games in development, but are scheduled for release beyond 2024 or currently carry no release date at all.</p>
</blockquote>
</li>
<li>
<p>总结一下上面的流程<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s11.ax1x.com/2024/02/24/pFUfYgP.png" alt=""></p>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>LangChain入门指南</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://cyborg2077.github.io/2024/01/26/LangChainPrimer/">https://cyborg2077.github.io/2024/01/26/LangChainPrimer/</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>Kyle Violet</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2024-01-26</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2024-02-24</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LangChain/"><div class="tags-punctuation"><svg class="faa-tada icon" style="height:1.1em;width:1.1em;fill:currentColor;position:relative;top:2px;margin-right:3px" aria-hidden="true"><use xlink:href="#icon-sekuaibiaoqian"></use></svg></div>LangChain</a></div></div><link rel="stylesheet" href="/css/coin.css" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">投喂作者</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.svg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/wechat.svg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.svg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/alipay.svg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></button></div><script defer="defer" src="/js/coin.js"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/02/07/NavicatSyncPit/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2.baidu.com/it/u=595920241,2439700946&amp;fm=253&amp;fmt=auto&amp;app=120&amp;f=JPEG?w=1422&amp;h=800" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Navicat在结构同步时的注意事项</div></div></a></div><div class="next-post pull-right"><a href="/2023/12/31/SelectForUpdate/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img0.baidu.com/it/u=4155835667,974645702&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=PNG?w=889&amp;h=500" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">SELECT FOR UPDATE的锁粒度</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="cols"><div class="col"><div class="container"><div class="front avatarPanel"><div class="inner"><div class="player-title">Attributes</div><div class="player-avatar"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2025/02/23/AMkCrfzyFsBQE3D.png" onerror="this.onerror=null;this.src='/assets/r1.png'" alt="avatar"/></div></div></div><div class="back attributesPanel"><div class="inner"><div class="player-lv">LV.16</div><div class="player-name">Kyle Violet</div><div class="attributes-value"><div class="attributes-value-item"><a href="/archives/"><div class="attributes">文章</div><div class="value-bar"><div class="value-bar-fill" style="width:75.50%"><div class="value-bar-fill-in" style="background: rgba(89, 230, 54,0.6)"></div></div></div><span>151/200</span></a></div><div class="attributes-value-item"><a href="/tags/"><div class="attributes">标签</div><div class="value-bar"><div class="value-bar-fill" style="width:56.00%"><div class="value-bar-fill-in" style="background: rgba(224, 20, 20, 0.6)"></div></div></div><span>112/200</span></a></div><div class="attributes-value-item"><a href="/categories/"><div class="attributes">分类</div><div class="value-bar"><div class="value-bar-fill" style="width:14.00%"><div class="value-bar-fill-in" style="background: rgba(30, 97, 226, 0.6)"></div></div></div><span>14/100</span></a></div></div></div></div></div></div><div class="col"><div class="container"><div class="front descriptionPanel"><div class="inner"><div class="player_description">The furthest distance in the world <br>ls not between life and death <br>But when l stand in front of you <br> Yet you don't know that l love you</div><div class="play-bottom"></div></div></div><div class="back buttonPanel"><div class="inner"><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Cyborg2077"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/Cyborg2077" target="_blank" title="Github"><svg class="social_icon iconfont" aria-hidden="true" style="width:1.15em;height:1.15em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-github-cyborg"></use></svg></a><a class="social-icon faa-parent animated-hover" href="http://wpa.qq.com/msgrd?v=3&amp;uin=1586385296&amp;site=qq&amp;menu=yes" target="_blank" title="QQ"><svg class="social_icon iconfont" aria-hidden="true" style="width:1.15em;height:1.15em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-QQ-cyborg"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://music.163.com/#/user/home?id=608935942" target="_blank" title="网抑云"><svg class="social_icon iconfont" aria-hidden="true" style="width:1.15em;height:1.15em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-netease-cyborg"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/160218990" target="_blank" title="Bilibili"><svg class="social_icon iconfont" aria-hidden="true" style="width:1.15em;height:1.15em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-bilibili-cyborg"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://steamcommunity.com/profiles/76561198851566538/" target="_blank" title="Steam"><svg class="social_icon iconfont" aria-hidden="true" style="width:1.15em;height:1.15em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-steam-cyborg"></use></svg></a></div><div class="play-bottom"></div></div></div></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><a class="faa-parent animated-hover"><svg class="faa-tada icon" style="height:25px;width:25px;fill:currentColor;position:relative;top:5px" aria-hidden="true"><use xlink:href="#icon-gonggao"></use></svg></a><span style="font-weight:bold">公告栏</span></div><div class="announcement_content">恰饭广告，一个文本类<font color="orange">AIGC</font>网站，<font color="orange">写各种作业的时候有大用！！</font><br>可以一键生成<font color="orange">开题报告</font>、<font color="orange">毕业论文</font>、<font color="orange">答辩PPT</font>等各种文档生成需求,近期还上线了新版降重模型,查重率支持降到个位数,目前还有<font color="orange">推广赚钱</font>活动，感兴趣的兄弟萌可以戳链接看看：<a href="https://www.kuaijiangchong.com.cn/" target="_blank">快降重--高端降重，遥遥领先</a></div><div id="welcome-info"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><svg class="meta_icon" style="width:22px;height:22px;position:relative;top:5px"><use xlink:href="#icon-mulu1"></use></svg><span style="font-weight:bold">目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">什么是LangChain</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">如何使用LangChain</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">LangChain的模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">LangChain 的主要特点</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">使用示例</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E7%A4%BA%E6%A8%A1%E6%9D%BF%EF%BC%88PromptTemplate%EF%BC%89"><span class="toc-number">5.1.</span> <span class="toc-text">提示模板（PromptTemplate）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LLM-Chain"><span class="toc-number">5.2.</span> <span class="toc-text">LLM Chain</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Retrieval-Chain%EF%BC%88%E5%9F%BA%E4%BA%8E%E6%A3%80%E7%B4%A2%E7%9A%84chain%EF%BC%89"><span class="toc-number">5.3.</span> <span class="toc-text">Retrieval Chain（基于检索的chain）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AE%E6%96%87%E6%A1%A3%E6%9E%84%E5%BB%BA%E5%90%91%E9%87%8F"><span class="toc-number">5.4.</span> <span class="toc-text">根据文档构建向量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E9%93%BE"><span class="toc-number">5.5.</span> <span class="toc-text">构建链</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4demo"><span class="toc-number">5.6.</span> <span class="toc-text">完整demo</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conversation-Retrieval-Chain%EF%BC%88%E5%AF%B9%E8%AF%9D%E6%A3%80%E7%B4%A2%E9%93%BE%EF%BC%89"><span class="toc-number">5.7.</span> <span class="toc-text">Conversation Retrieval Chain（对话检索链）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Agent"><span class="toc-number">5.8.</span> <span class="toc-text">Agent</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E6%9C%8D%E5%8A%A1"><span class="toc-number">5.9.</span> <span class="toc-text">构建服务</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">链的概念（补充）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%BA%E5%BA%8F%E9%93%BE%EF%BC%88SequentialChains%EF%BC%89"><span class="toc-number">6.1.</span> <span class="toc-text">顺序链（SequentialChains）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E9%93%BE%E7%BB%84%E5%90%88"><span class="toc-number">6.2.</span> <span class="toc-text">多链组合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B7%AF%E7%94%B1%E9%93%BE"><span class="toc-number">6.3.</span> <span class="toc-text">路由链</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">7.</span> <span class="toc-text">代理的概念（补充）</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-color: transparent;"><div id="footer-wrap"><div id="ft"><div class="ft-item-1"><div class="t-top"><div class="t-t-l"><p class="ft-t t-l-t">格言🧬</p><div class="bg-ad"><div>离我们最近的星星有4.25光年远，我们许的愿望至少都要花上9年才能成真。————所以，向宇宙下订单要有耐心。✨</div><div class="btn-xz-box"><a class="btn-xz" target="_blank" rel="noopener" href="https://stellarium.org/">点击开启星辰之旅</a></div></div></div><div class="t-t-r"><p class="ft-t t-l-t">猜你想看💡</p><ul class="ft-links"><li><a href="/moments/">我的说说</a><a href="/box/nav/">网址导航</a></li><li><a href="/social/link/">我的朋友</a><a href="/comments/">留点什么</a></li><li><a href="/personal/about/">关于作者</a><a href="/archives/">文章归档</a></li><li><a href="/categories/">文章分类</a><a href="/tags/">文章标签</a></li><li><a href="/box/fitness/">健身日寄</a><a href="/secret/">记忆胶囊</a></li></ul></div></div></div><div class="ft-item-2"><p class="ft-t">推荐友链⌛</p><div class="ft-img-group"><div class="img-group-item"><a href="https://cyborg2077.github.io/" title="Kyle's Blog"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2025/02/23/AMkCrfzyFsBQE3D.png" alt=""/></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://pumpkin-ovo.github.io/" title="南瓜酱(✘_✘)"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/11/23/YO4BaHEeok8CmFx.png" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div></div></div></div><div class="copyright"><span><b>&copy;2021-2025</b></span><span><b>&nbsp;&nbsp;By Kyle Violet</b></span></div><div id="workboard"></div><pghbdages><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v6.3.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Frame-Hexo-blue.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v4.3.1"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Theme-Butterfly-6513df.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" title="本站采用多线部署，主线路托管于Vercel"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Hosted-Vercel-brightgreen.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://user.51.la/" style="margin-inline:5px" title="本站数据分析得益于51la技术支持"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Analytics-51la-3db1eb.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://icp.gov.moe/?keyword=20226665" style="margin-inline:5px" title="本站已加入萌ICP豪华套餐，萌ICP备20226665号"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/萌ICP备-20226665-fe1384.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://bitiful.dogecast.com/buckets" style="margin-inline:5px" title="本网站经Service Worker分流至缤纷云对象存储"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src=" https://sourcebucket.s3.ladydaily.com/badge/Bucket-缤纷云-9c62da.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://www.netdun.net/" style="margin-inline:5px" title="本站使用网盾星球提供CDN加速与防护"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/CDN-网盾星球-fff2cc.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本网站源码由Github提供存储仓库"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src=" https://sourcebucket.s3.ladydaily.com/badge/Source-Github-d021d6.svg" alt=""/></a></pghbdages></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="share" type="button" title="右键模式" onclick="changeMouseMode()"><i class="fas fa-mouse"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog right_side"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button class="share" type="button" title="分享链接" onclick="share()"><i class="fas fa-share-nodes"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i><span id="percent">0<span>%</span></span></button><button id="go-down" type="button" title="直达底部" onclick="btf.scrollToDest(document.body.scrollHeight, 500)"><i class="fas fa-arrow-down"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();"><i class="fa fa-search"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-post"><a class="rightMenu-item" href="#post-comment"><i class="fas fa-comment"></i><span>空降评论</span></a><a class="rightMenu-item" href="javascript:rmf.copyWordsLink()"><i class="fa fa-link"></i><span>复制本文地址</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:randomPost()"><i class="fa fa-paper-plane"></i><span>随便逛逛</span></a><a class="rightMenu-item" href="javascript:switchNightMode();"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="/personal/about/"><i class="fa fa-info-circle"></i><span>关于博客</span></a><a class="rightMenu-item" href="javascript:toggleWinbox();"><i class="fas fa-cog"></i><span>美化设置</span></a><a class="rightMenu-item" href="javascript:rmf.fullScreen();"><i class="fas fa-expand"></i><span>切换全屏</span></a><a class="rightMenu-item" href="javascript:window.print();"><i class="fa-solid fa-print"></i><span>打印页面</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><script async="async">var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())
setTimeout(function(){preloader.endLoading();}, 5000);
document.getElementById('loading-box').addEventListener('click',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>function loadGiscus () {
  let nowTheme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'light'

  const config = Object.assign({
    src: 'https://giscus.app/client.js',
    'data-repo': 'Cyborg2077/Cyborg2077.github.io',
    'data-repo-id': 'R_kgDOGflxEw',
    'data-category-id': 'DIC_kwDOGflxE84CRxKp',
    'data-mapping': 'pathname',
    'data-theme': nowTheme,
    'data-reactions-enabled': '1',
    crossorigin: 'anonymous',
    async: true
  },null)

  let ele = document.createElement('script')
  for (let key in config) {
    ele.setAttribute(key, config[key])
  }
  document.getElementById('giscus-wrap').insertAdjacentElement('afterbegin',ele)
}

function changeGiscusTheme () {
  const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'light'

  function sendMessage(message) {
    const iframe = document.querySelector('iframe.giscus-frame');
    if (!iframe) return;
    iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
  }

  sendMessage({
    setConfig: {
      theme: theme
    }
  });
}

if ('Giscus' === 'Giscus' || !true) {
  if (true) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
  else loadGiscus()
} else {
  function loadOtherComment () {
    loadGiscus()
  }
}</script></div><div class="aplayer no-destroy" data-id="6831019121" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-preload="none" data-autoplay="true" muted></div><div id="vcomments"></div><script> new Valine({ el:'#vcomment', appId:'06KXhkKAB9IH7PreBEBl0WL0-MdYXbMMI', appKey:'JApVWPKkDT6qzbMdWfKlva41' })</script><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async data-pjax src="/js/txmap.js"></script><script async src="https://cdn1.tianli0.top/npm/vue@2.6.14/dist/vue.min.js"></script><script async src="https://cdn1.tianli0.top/npm/element-ui@2.15.6/lib/index.js"></script><script async src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script><script defer type="text/javascript" src="https://cdn1.tianli0.top/npm/sweetalert2@8.19.0/dist/sweetalert2.all.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script defer src="https://cdn1.tianli0.top/gh/nextapps-de/winbox/dist/winbox.bundle.min.js"></script><script async src="//at.alicdn.com/t/c/font_3586335_hsivh70x0fm.js"></script><script async src="//at.alicdn.com/t/c/font_3636804_gr02jmjr3y9.js"></script><script async src="//at.alicdn.com/t/c/font_3612150_kfv55xn3u2g.js"></script><script async src="//at.alicdn.com/t/c/font_3049706_xky4v9paku7.js"></script><script async src="//at.alicdn.com/t/c/font_3049706_m3wrww27lm.js"></script><script async src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><canvas id="universe"></canvas><canvas id="snow"></canvas><script defer src="/js/fomal.js"></script><script async src="//at.alicdn.com/t/c/font_4244550_myoln7t3mdn.js"></script><script id="canvas_nest" defer="defer" color="255,192,203" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/click-show-text.min.js" data-mobile="false" data-text="富强,民主,文明,和谐,自由,平等,公正,法制,爱国,敬业,诚信,友善" data-fontsize="15px" data-random="false" async="async"></script><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.12/metingjs/Meting.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["link[rel=\"canonical\"]","meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#web_bg",".js-pjax","#bibi","body > title","#app","#tag-echarts","#posts-echart","#categories-echarts"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://cyborg2077.github.io/categories/学习笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍡 Kyleの学习笔记 (67)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://cyborg2077.github.io/categories/面试题/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍼 Kyleの面试题总结 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://cyborg2077.github.io/categories/力扣/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍉 Kyleの刷题日志 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://cyborg2077.github.io/categories/杂谈/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍟 Kyleの杂谈 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://cyborg2077.github.io/categories/随写/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍨 Kyleの随写 (15)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://cyborg2077.github.io/categories/实用教程/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍥 Kyleの实用教程 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://cyborg2077.github.io/categories/" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #e9e9e9;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: var(--text-bg-hover)}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu@1.1.6/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var qweather_key = 'e57e16d653c34fc49b5d1cc0713eb9ab';
  var gaud_map_key = 'e2b04289e870b005374ee030148d64fd&s=rsv3';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '112.6534116,27.96920845';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu@1.1.6/lib/clock.min.js"></script><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><div id="ghbdages" style="overflow:hidden;max-height:90px;height:auto;text-align:center;margin-top:10px"><div class="swiper-wrapper"><div class="swiper-slide"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v5.4.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v4.1.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本站项目由Github托管"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a></div><div class="swiper-slide"><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></div></div></div><style>a.github-badge:hover:before {display:none}</style>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-footer-beautify/lib/swiperbdage_init.min.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/11/05/NewFeaturesOfJava8/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic3.zhimg.com%2Fv2-dbe4189cad999946abdcd174fba140ea_r.jpg&amp;refer=http%3A%2F%2Fpic3.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1651217592&amp;t=44946406f8e7b9ed15f483e0495b33c9" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-11-05</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/11/05/NewFeaturesOfJava8/&quot;);" href="javascript:void(0);" alt="">Java 8新特性</a><div class="blog-slider__text">Java8新特性，之前只是草草看了一下，后来发现stream流操作挺好用的，来补一下票</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/11/05/NewFeaturesOfJava8/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/22/MeassageQueue/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic3.zhimg.com%2Fv2-dbe4189cad999946abdcd174fba140ea_r.jpg&amp;refer=http%3A%2F%2Fpic3.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1651217592&amp;t=44946406f8e7b9ed15f483e0495b33c9" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-22</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/22/MeassageQueue/&quot;);" href="javascript:void(0);" alt="">MeassageQueue</a><div class="blog-slider__text">消息队列相关学习记录</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/22/MeassageQueue/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/21/Docker/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2.baidu.com/it/u=1767752488,2158562887&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=JPEG?w=932&amp;h=500" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-21</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/21/Docker/&quot;);" href="javascript:void(0);" alt="">Docker</a><div class="blog-slider__text">Docker实用篇学习笔记</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/21/Docker/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/12/24/ElasticSearch/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2.baidu.com/it/u=1767752488,2158562887&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=JPEG?w=932&amp;h=500" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-12-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/12/24/ElasticSearch/&quot;);" href="javascript:void(0);" alt="">ElasticSearch</a><div class="blog-slider__text">分布式搜索引擎</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/12/24/ElasticSearch/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/11/08/SpringCloud/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2.baidu.com/it/u=1767752488,2158562887&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=JPEG?w=932&amp;h=500" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-11-08</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/11/08/SpringCloud/&quot;);" href="javascript:void(0);" alt="">SpringCloud</a><div class="blog-slider__text">SpringCloud学习笔记</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/11/08/SpringCloud/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/09/29/ReggieTakeOut/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic3.zhimg.com%2Fv2-7f659641f358fab5aa28640c3f62978a_r.jpg&amp;refer=http%3A%2F%2Fpic3.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1645330580&amp;t=3c5f025bbdcc09fad7cfd3e8aae5ccc9" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/09/29/ReggieTakeOut/&quot;);" href="javascript:void(0);" alt="">瑞吉外卖</a><div class="blog-slider__text">瑞吉外卖实战项目</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/09/29/ReggieTakeOut/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/10/22/RedisPractice/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img0.baidu.com/it/u=518815500,4294667560&amp;fm=253&amp;fmt=auto&amp;app=120&amp;f=JPEG?w=1422&amp;h=800" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-10-22</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/10/22/RedisPractice/&quot;);" href="javascript:void(0);" alt="">Redis实战篇</a><div class="blog-slider__text">Redis实战篇，包含优惠券秒杀，分布式锁，消息队列用户签到等功能</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/10/22/RedisPractice/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2023/10/28/RDelayedQueue/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img2.baidu.com/it/u=4052816064,1042373333&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=JPEG?w=889&amp;h=500" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-10-28</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2023/10/28/RDelayedQueue/&quot;);" href="javascript:void(0);" alt="">Redisson延迟队列实现倒计时任务</a><div class="blog-slider__text">项目里有个场景需要做延迟任务</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2023/10/28/RDelayedQueue/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('gitZone');
      var item_html = '<div class="recent-post-item" id="gitcalendarBar" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 320px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('gitZone') && (location.pathname ==='/site/census/'|| '/site/census/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("/api?Cyborg2077",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'Cyborg2077')
    }
  </script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"log":false});</script></body></html>